\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ddpm,yang2023diffusion}
\citation{pmlr-v37-sohl-dickstein15}
\citation{Barcel'o2024AvoidingMC}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{[1][1][]1}}
\citation{pmlr-v37-sohl-dickstein15}
\citation{Chung2024CFGMC}
\citation{Barcel'o2024AvoidingMC}
\citation{yang2023diffusion}
\citation{Aithal2024UnderstandingHI}
\citation{Nijkamp2019OnTA}
\citation{ddpm}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\newlabel{sec:related@cref}{{[section][2][]2}{[1][1][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Sampling Guidance Methods}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Coverage Analysis}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{2}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{2}{Background}{section.3}{}}
\newlabel{sec:background@cref}{{[section][3][]3}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Setting}{2}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{3}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{3}{Method}{section.4}{}}
\newlabel{sec:method@cref}{{[section][4][]4}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Architecture}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Training}{3}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Sampling}{3}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{3}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{3}{Experimental Setup}{section.5}{}}
\newlabel{sec:experimental@cref}{{[section][5][]5}{[1][3][]3}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance comparison across guidance variants (ranges show min/max across datasets)\relax }}{4}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:results}{{1}{4}{Performance comparison across guidance variants (ranges show min/max across datasets)\relax }{table.caption.1}{}}
\newlabel{tab:results@cref}{{[table][1][]1}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Implementation Details}{4}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{4}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{4}{Results}{section.6}{}}
\newlabel{sec:results@cref}{{[section][6][]6}{[1][4][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Quantitative Analysis}{4}{subsection.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces KL divergence across methods and datasets. All guidance variants (colored) perform worse than baseline (black).\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:kl_comparison}{{1}{5}{KL divergence across methods and datasets. All guidance variants (colored) perform worse than baseline (black).\relax }{figure.caption.2}{}}
\newlabel{fig:kl_comparison@cref}{{[figure][1][]1}{[1][5][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Dataset-Specific Performance}{5}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Training Dynamics}{5}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Sample Quality}{5}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions and Future Work}{5}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{5}{Conclusions and Future Work}{section.7}{}}
\newlabel{sec:conclusion@cref}{{[section][7][]7}{[1][5][]5}}
\citation{Aithal2024UnderstandingHI}
\citation{vae,gan}
\citation{yang2023diffusion}
\citation{lu2024aiscientist}
\bibstyle{iclr2024_conference}
\bibdata{references}
\bibcite{Aithal2024UnderstandingHI}{{1}{2024}{{Aithal et~al.}}{{Aithal, Maini, Lipton, and Kolter}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Generated samples comparison. Top: baseline. Bottom: guided variants showing artifacts and density distortions.\relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{fig:generated_samples}{{2}{6}{Generated samples comparison. Top: baseline. Bottom: guided variants showing artifacts and density distortions.\relax }{figure.caption.3}{}}
\newlabel{fig:generated_samples@cref}{{[figure][2][]2}{[1][5][]6}}
\bibcite{Barcel'o2024AvoidingMC}{{2}{2024}{{Barcel'o et~al.}}{{Barcel'o, Alc'azar, and Tobar}}}
\bibcite{Chung2024CFGMC}{{3}{2024}{{Chung et~al.}}{{Chung, Kim, Park, Nam, and Ye}}}
\bibcite{gan}{{4}{2014}{{Goodfellow et~al.}}{{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio}}}
\bibcite{ddpm}{{5}{2020}{{Ho et~al.}}{{Ho, Jain, and Abbeel}}}
\bibcite{vae}{{6}{2014}{{Kingma \& Welling}}{{Kingma and Welling}}}
\bibcite{lu2024aiscientist}{{7}{2024}{{Lu et~al.}}{{Lu, Lu, Lange, Foerster, Clune, and Ha}}}
\bibcite{Nijkamp2019OnTA}{{8}{2019}{{Nijkamp et~al.}}{{Nijkamp, Hill, Han, Zhu, and Wu}}}
\bibcite{pmlr-v37-sohl-dickstein15}{{9}{2015}{{Sohl-Dickstein et~al.}}{{Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli}}}
\bibcite{yang2023diffusion}{{10}{2023}{{Yang et~al.}}{{Yang, Zhang, Song, Hong, Xu, Zhao, Zhang, Cui, and Yang}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Training loss curves. Baseline (black) shows faster convergence and lower final loss than guided variants.\relax }}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:train_loss}{{3}{7}{Training loss curves. Baseline (black) shows faster convergence and lower final loss than guided variants.\relax }{figure.caption.4}{}}
\newlabel{fig:train_loss@cref}{{[figure][3][]3}{[1][5][]7}}
\ttl@finishall
\gdef \@abspage@last{8}
