# Title: Hybrid Adaptive Embeddings for Low-Dimensional Diffusion Models
# Experiment description: 1) Design new embedding layer that combines sinusoidal basis with learned modulation. 2) Keep core architecture identical for fair comparison. 3) Evaluate on all datasets using same metrics. 4) Analyze how modulation patterns vary across timesteps.

## Run 0: Baseline
Results: {'circle': {'training_time': 34.17870044708252, 'eval_loss': 0.43525103938853954, 'inference_time': 0.12008213996887207, 'kl_divergence': 0.3389495344946721}, 'dino': {'training_time': 33.63431358337402, 'eval_loss': 0.6616260491673599, 'inference_time': 0.12255191802978516, 'kl_divergence': 1.0424222911130459}, 'line': {'training_time': 33.44674801826477, 'eval_loss': 0.8031019351976302, 'inference_time': 0.11939525604248047, 'kl_divergence': 0.15379776690960525}, 'moons': {'training_time': 33.61119055747986, 'eval_loss': 0.6135321608589738, 'inference_time': 0.12108755111694336, 'kl_divergence': 0.10051708186608005}}
Description: Baseline results with standard sinusoidal embeddings.

## Run 1: Basic Learned Modulation
Results: {'circle': {'training_time': 36.61597228050232, 'eval_loss': 0.4316153442463302, 'inference_time': 0.127960205078125, 'kl_divergence': 0.3506045242336704}, 'dino': {'training_time': 36.03818130493164, 'eval_loss': 0.6671025292647769, 'inference_time': 0.12571001052856445, 'kl_divergence': 1.1173113564211328}, 'line': {'training_time': 36.21130609512329, 'eval_loss': 0.8008388703131615, 'inference_time': 0.12624502182006836, 'kl_divergence': 0.16723218989644809}, 'moons': {'training_time': 36.14766764640808, 'eval_loss': 0.6139350854374869, 'inference_time': 0.1276705265045166, 'kl_divergence': 0.09635574901706938}}
Description: Added simple learned modulation parameters that scale the sinusoidal embeddings. Results show:
- Slightly improved eval_loss on circle dataset (0.4316 vs 0.4352)
- Comparable performance on other datasets
- Small increase in training time (~3s) likely due to additional parameters
- KL divergence shows similar or slightly worse sample quality
Conclusion: Basic modulation shows promise but needs more sophisticated time-dependent adaptation.

## Run 2: Timestep-Conditioned Modulation
Results: {'circle': {'training_time': 45.76345229148865, 'eval_loss': 0.43330059972260615, 'inference_time': 0.15790390968322754, 'kl_divergence': 0.35058440698147475}, 'dino': {'training_time': 45.19839596748352, 'eval_loss': 0.6621031495921142, 'inference_time': 0.1620948314666748, 'kl_divergence': 1.513520520170212}, 'line': {'training_time': 45.36561298370361, 'eval_loss': 0.7991727486900662, 'inference_time': 0.16071867942810059, 'kl_divergence': 0.15480078268381714}, 'moons': {'training_time': 45.681315898895264, 'eval_loss': 0.6135843520426689, 'inference_time': 0.17147183418273926, 'kl_divergence': 0.09638519422036192}}
Description: Added timestep-conditioned modulation network (small MLP) that learns to scale sinusoidal embeddings based on input timestep. Results show:
- Training time increased significantly (~10s) due to more complex modulation network
- Eval losses remained comparable to Run 1
- KL divergence increased for dino dataset (1.51 vs 1.12) suggesting potential overfitting
- Other datasets maintained similar sample quality
Conclusion: Dynamic modulation didn't provide clear benefits over static modulation, possibly due to limited capacity of the small MLP. More sophisticated attention-based modulation may help.

## Run 3: Attention-Based Modulation
Results: {'circle': {'training_time': 53.45984601974487, 'eval_loss': 0.4906680083183376, 'inference_time': 0.681804895401001, 'kl_divergence': 1.8346935153035067}, 'dino': {'training_time': 52.81509804725647, 'eval_loss': 0.7280742783680596, 'inference_time': 0.6951544284820557, 'kl_divergence': 5.774732817915213}, 'line': {'training_time': 53.37069821357727, 'eval_loss': 0.8050570090103637, 'inference_time': 0.6787593364715576, 'kl_divergence': 0.19706579380720107}, 'moons': {'training_time': 53.105048179626465, 'eval_loss': 0.6196140037168323, 'inference_time': 0.68792724609375, 'kl_divergence': 0.4271388813651179}}
Description: Replaced MLP modulation with attention mechanism to learn frequency band importance. Results show:
- Significant increase in training time (~8s over Run 2) due to attention computation
- Worse eval_loss across all datasets (e.g. circle 0.49 vs 0.43 in Run 2)
- Much higher KL divergence (1.83 vs 0.35 for circle, 5.77 vs 1.51 for dino)
- Inference time increased 4x due to attention computation
Conclusion: Attention-based modulation performed worse than simpler approaches, likely because:
1. The small embedding dimensions (128) don't provide enough signal for attention to be effective
2. The additional complexity may be harming optimization
3. The 2D nature of the data may not benefit from attention's strengths

## Generated Plots

### train_loss.png
This figure shows the training loss curves across all experimental runs (Baseline, Static Modulation, MLP Modulation, and Attention Modulation) for each of the four datasets (circle, dino, line, moons). Key observations:
- The subplots clearly show how different modulation approaches affect convergence
- Static Modulation (Run 1) shows slightly better final loss than Baseline on circle dataset
- MLP Modulation (Run 2) maintains similar loss curves to Static Modulation but with more variance
- Attention Modulation (Run 3) shows significantly worse convergence behavior across all datasets
- The smoothing window of 25 steps helps visualize overall trends while preserving important variations

### generated_images.png
This figure visualizes samples generated by each method (rows) for each dataset (columns). Key observations:
- Baseline samples show the expected quality for each dataset shape
- Static Modulation produces slightly more concentrated samples for circle dataset
- MLP Modulation maintains similar sample quality to Static Modulation
- Attention Modulation shows clear degradation in sample quality, particularly for dino dataset where samples lose the dinosaur shape
- The alpha blending (0.2) helps visualize the density distribution of samples
- Each subplot is labeled with both the method (y-axis) and dataset (x-axis) for clear interpretation
